{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "\n",
    "## Data science question\n",
    "\n",
    "My original data science question was: Predict ratings of instant noodle products. As mentionned in class the data science question itself often does not include the goal or how the model's usefulness in the real world would be measured. For this purpose we define the utility function below.\n",
    "\n",
    "## Utility function\n",
    "\n",
    "The model would be used at a grocery store when one wants to choose between two or more ramen products. The product with the highest rating would be purchased. Overtime the desire is for the user of the model to consume higher rated ramen on average.\n",
    "\n",
    "To simplify, our utility function can output a 1 when the ordering of the model is equal to the ordering of the actual ramen ratings.\n",
    "\n",
    "Our utility function in this case is binary:\n",
    "\n",
    "$$\n",
    "U(x_1, x_2 |y_1 \\geq y_2) = \n",
    "     \\begin{cases}\n",
    "       \\text{0} &\\quad\\text{if $y_1 < y_2$}\\\\\n",
    "       \\text{1} &\\quad\\text{if $y_1 \\geq y_2$}\\\\\n",
    "     \\end{cases}\n",
    "$$\n",
    "\n",
    "## Loading data & models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "ebm_val_data = pd.read_csv('../clean_data/ebm_val_data.csv')\n",
    "linear_val_data = pd.read_csv('../clean_data/linear_val_data.csv')\n",
    "\n",
    "y_val = ebm_val_data['Stars']\n",
    "\n",
    "X_ebm = ebm_val_data.drop(columns=['Stars'])\n",
    "X_lm = linear_val_data.drop(columns=['Stars'])\n",
    "\n",
    "# Load models\n",
    "lm = load('../models/linear.joblib')\n",
    "ebm = load('../models/ebm.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_lm = lm.predict(X_lm)\n",
    "y_hat_ebm = ebm.predict(X_ebm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utility_score(y, y_hat):\n",
    "    offset = 0\n",
    "    score = 0\n",
    "    perfect_score = 0\n",
    "    for i in range(len(y)):\n",
    "        for j in range(len(y) - offset):\n",
    "            if i != j + offset:\n",
    "                if y_hat[i] >= y_hat[j + offset] and y[i] >= y[j + offset]:\n",
    "                    score += 1\n",
    "                perfect_score += 1\n",
    "        offset += 1\n",
    "    return score, perfect_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lms correctly picked the highest rated ramen 31.67% of the time.\n"
     ]
    }
   ],
   "source": [
    "lm_utility_score = get_utility_score(y_val, y_hat_lm)\n",
    "print(\"Lms correctly picked the highest rated ramen {0:.2f}% of the time.\".format(100*(lm_utility_score[0]/lm_utility_score[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ebms correctly picked the highest rated ramen 33.85% of the time.\n"
     ]
    }
   ],
   "source": [
    "ebm_utility_score = get_utility_score(y_val, y_hat_ebm)\n",
    "print(\"Ebms correctly picked the highest rated ramen {0:.2f}% of the time.\".format(100*(ebm_utility_score[0]/ebm_utility_score[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we find that, altough the models would give a smaller error when attempting to calculate the specific star rating of a ramen product than a human, it is better to guess between two ramen products than to use the linear and EBM models to choose which ramen to eat. Let's see if we can do better than guessing by using a fixed prediction of rating based on the average of the star ratings by brands.\n",
    "\n",
    "\n",
    "## Simple approach\n",
    "\n",
    "We start by importing our raw data and obtaining the average star rating by brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rr_df = pd.read_csv('../raw_data/ramen_ratings.csv');\n",
    "\n",
    "# Remove unrated entries\n",
    "rated_df = rr_df[~(rr_df.Stars == \"Unrated\")]\n",
    "\n",
    "# Change column type to float\n",
    "rated_df_with_types = rated_df.copy()\n",
    "rated_df_with_types.Stars = rated_df_with_types.Stars.astype('float')\n",
    "\n",
    "# Get star rating by brand\n",
    "stars_by_brand = rated_df_with_types[['Stars', 'Brand']].groupby(['Brand']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating(row):\n",
    "    return stars_by_brand.loc[row['Brand']].Stars\n",
    "\n",
    "predictions = rated_df_with_types.apply(get_rating, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicion using the average brand rating correctly picked the highest rated ramen 47.45% of the time.\n"
     ]
    }
   ],
   "source": [
    "avg_brand_score = get_utility_score(rated_df_with_types.Stars.values, predictions.values)\n",
    "print(\"Predicion using the average brand rating correctly picked the highest rated ramen {0:.2f}% of the time.\".format(100*(avg_brand_score[0]/avg_brand_score[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "With the current dataset, we weren't able to create a model which could choose the highest rated ramen between two ramen products with a better accuracy than a random guess. In this case, using the average of the Brand's rating resulted in more accurate predictions than model trained on our features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
